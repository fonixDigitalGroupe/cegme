# PATCH URGENT : Scraping Fonctionnel sur OVH

## üéØ Ce qui a √©t√© modifi√©

**Fichier** : `app/Http/Controllers/Admin/ScrapingController.php`

**Probl√®me r√©solu** : exec() et proc_open() sont d√©sactiv√©s sur OVH mutualis√©, emp√™chant le scraping de fonctionner.

**Solution** : Le scraping s'ex√©cute maintenant de mani√®re synchrone (dans la m√™me requ√™te HTTP) au lieu d'essayer de lancer un processus s√©par√©.

## üì¶ D√©ploiement en Production (3 m√©thodes)

### M√©thode 1 : Via GitHub + Git Pull (RECOMMAND√â)

#### √âtape 1 : Commit et Push (LOCAL)

```bash
cd "/home/fonix-sa/Bureau/Fonix projects/Cegme/cegme"

# Ajouter les modifications
git add app/Http/Controllers/Admin/ScrapingController.php

# Commit
git commit -m "Fix: Scraping synchrone pour compatibilit√© OVH (sans exec)"

# Push vers GitHub
git push origin main
```

#### √âtape 2 : Pull sur le serveur (OVH)

**Via SSH** (si vous avez acc√®s) :
```bash
ssh votre-utilisateur@dwesta.cegme.net
cd /chemin/vers/votre/projet

# Sauvegarder au cas o√π
cp -r app/Http/Controllers app/Http/Controllers.backup

# R√©cup√©rer les changements
git pull origin main

# Nettoyer le cache
php artisan config:clear
php artisan route:clear
php artisan cache:clear
```

**Via le panneau OVH** (si pas d'acc√®s SSH) :
- Si vous avez configur√© le d√©ploiement automatique Git ‚Üí Il se d√©ploiera automatiquement
- Sinon, utilisez la M√©thode 2 (FTP)

---

### M√©thode 2 : Via FTP (Sans Git)

#### √âtape 1 : Pr√©parer le fichier

1. Le fichier modifi√© est : `app/Http/Controllers/Admin/ScrapingController.php`
2. Il se trouve dans : `/home/fonix-sa/Bureau/Fonix projects/Cegme/cegme/`

#### √âtape 2 : Upload via FTP

1. **Connectez-vous au FTP** de dwesta.cegme.net
2. **Naviguez vers** : `app/Http/Controllers/Admin/`
3. **Sauvegarde** : 
   - T√©l√©chargez d'abord `ScrapingController.php` actuel
   - Renommez-le en `ScrapingController.php.backup`
4. **Upload** :
   - Uploadez le nouveau `ScrapingController.php`
   - √âcrasez l'ancien fichier

#### √âtape 3 : Nettoyer le cache

Via le panneau OVH, si possible :
```bash
php artisan config:clear
php artisan route:clear
php artisan cache:clear
```

Sinon, attendez quelques minutes que le cache expire automatiquement.

---

### M√©thode 3 : Copier-Coller Manuel (Dernier recours)

Si vous ne pouvez pas utiliser FTP ou Git :

1. **Via le panneau OVH** ou un √©diteur de fichiers web
2. **Ouvrez** : `app/Http/Controllers/Admin/ScrapingController.php`
3. **Trouvez la m√©thode** `start()` (ligne 40-108)
4. **Remplacez tout le contenu** de cette m√©thode par le nouveau code

---

## ‚úÖ V√©rification Apr√®s D√©ploiement

### 1. Tester le scraping

1. Allez sur `https://www.dwesta.cegme.net/admin/scraping`
2. Cliquez sur **"D√©marrer le scraping"**
3. **R√©sultat attendu** :
   - ‚úÖ "Vidage de la base..." appara√Æt
   - ‚úÖ Puis "Scraping de AFD..." (ou autre source)
   - ‚úÖ Les offres commencent √† appara√Ætre
   - ‚úÖ La progression avance normalement

### 2. V√©rifier les logs

Si √ßa ne marche toujours pas, t√©l√©chargez le fichier :
```
storage/logs/laravel.log
```

Cherchez les lignes r√©centes pour voir l'erreur exacte.

### 3. V√©rifier dans phpMyAdmin

1. Ouvrez phpMyAdmin
2. S√©lectionnez votre base de donn√©es
3. Cliquez sur la table `offres`
4. V√©rifiez que des nouvelles donn√©es apparaissent pendant le scraping

---

## ‚ö†Ô∏è Limitations du Mode Synchrone

### Avantages ‚úÖ
- Fonctionne sur OVH mutualis√© (et tous les h√©bergements)
- Pas besoin d'activer exec() ou proc_open()
- Plus simple √† d√©boguer

### Inconv√©nients ‚ö†Ô∏è
- **Timeout possible** : Si le serveur limite le temps d'ex√©cution √† 60-120 secondes
- **Connexion doit rester ouverte** : Si vous fermez l'onglet pendant le scraping, √ßa s'arr√™te

### Solutions aux limitations

**Si timeout apr√®s 1-2 minutes** :

1. **R√©duire le nombre de sources** scrap√©es simultan√©ment
2. **Scraper source par source** manuellement :
   - D√©sactiver toutes les r√®gles sauf une
   - Lancer le scraping
   - Attendre la fin
   - Activer une autre r√®gle
   - Relancer avec "Conserver les offres existantes"

**Si vous fermez l'onglet** :
- Le scraping s'arr√™te
- Pas grave, relancez-le avec "Conserver les offres existantes"

---

## üîß Param√®tres PHP Modifi√©s

Le patch modifie ces param√®tres pendant l'ex√©cution :

```php
set_time_limit(300); // 5 minutes maximum
ini_set('max_execution_time', '300');
```

**Note** : OVH peut avoir des limites strictes qui emp√™chent ces modifications.
Si le scraping timeout apr√®s 60-120 secondes, c'est normal sur un h√©bergement mutualis√©.

---

## üí° Alternatives si le scraping timeout

### Option A : Cron Job (Configuration OVH)

Cr√©ez une t√¢che planifi√©e dans le panneau OVH :

```bash
cd /chemin/vers/projet && php artisan schedule:run
```

Fr√©quence : Toutes les heures ou tous les jours

### Option B : Scraping manuel source par source

1. Allez dans "R√®gles de filtrage"
2. D√©sactivez toutes les sources sauf une
3. Lancez le scraping
4. Attendez qu'il finisse
5. Activez la source suivante
6. Relancez avec "Conserver les offres existantes" coch√©

---

## üìä Diff√©rences avec votre environnement local

| Aspect | Local | Production OVH |
|--------|-------|----------------|
| exec() / proc_open() | ‚úÖ Activ√© | ‚ùå D√©sactiv√© |
| Temps d'ex√©cution max | ‚è±Ô∏è Illimit√© | ‚è±Ô∏è 60-120 sec |
| Processus s√©par√©s | ‚úÖ Oui | ‚ùå Non |
| Mode | Asynchrone | **Synchrone** |

---

## üéØ R√©sultat Attendu

Apr√®s le d√©ploiement, au lieu de rester bloqu√© √† "Vidage...", vous devriez voir :

```
‚úì Vidage de la base de donn√©es...
‚úì Scraping de AFD... 12 offres pertinentes trouv√©es
‚úì Scraping de World Bank... 25 offres pertinentes trouv√©es
‚úì Scraping de BDEAC... 8 offres pertinentes trouv√©es
...
‚úì Scraping termin√© - 73 offres au total
```

---

## üìù Checklist de D√©ploiement

- [ ] Fichier `ScrapingController.php` modifi√© upload√© sur le serveur
- [ ] Cache Laravel nettoy√© (`php artisan cache:clear`)
- [ ] Test du scraping effectu√©
- [ ] Au moins une source scrape avec succ√®s
- [ ] Offres visibles dans phpMyAdmin et sur le site

---

**Temps de d√©ploiement** : 5-10 minutes  
**Complexit√©** : Moyenne  
**Risque** : Faible (seule la fonction de scraping est modifi√©e)
